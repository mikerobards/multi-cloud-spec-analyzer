import os
from typing import TypedDict
from dotenv import load_dotenv

# LangChain / LangGraph imports
from langgraph.graph import StateGraph, END
from langchain_google_vertexai import ChatVertexAI
from langchain_openai import AzureChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

# Load environment variables from a .env file if you have one
load_dotenv()

# --- CONFIGURATION ---
# 1. Google Cloud (The "Reader" Brain)
# We use Gemini 1.5 Pro because it has a massive context window (1M+ tokens),
# perfect for reading huge requirements documents.
# Ensure you run `gcloud auth application-default login` in your terminal first.
GCP_PROJECT_ID = os.getenv("GCP_PROJECT_ID", "your-google-cloud-project-id")
gemini_model = ChatVertexAI(
    model_name="gemini-1.5-pro",
    temperature=0,
    max_output_tokens=2048,
    project=GCP_PROJECT_ID
)

# 2. Azure OpenAI (The "Writer" Brain)
# We use GPT-4 on Azure to format the output. This simulates a common enterprise
# constraint where final artifacts must be generated by a specific compliant provider.
# If you don't have Azure keys yet, you can swap this class for standard `ChatOpenAI`.
azure_model = AzureChatOpenAI(
    azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4"),
    openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT", "https://your-org.openai.azure.com/"),
    api_key=os.getenv("AZURE_OPENAI_API_KEY")
)

# --- THE AGENT STATE ---
# In LangGraph, "State" is the shared memory that passes between steps.
# It works like a dictionary that gets updated as the agent moves through the graph.
class AgentState(TypedDict):
    spec_text: str      # Input: The raw requirement text
    analysis_gaps: str  # Intermediate: The gaps found by Gemini
    ado_tickets: str    # Output: The final tickets formatted by Azure

# --- NODES (The Steps) ---

def analyze_requirements_node(state: AgentState):
    """
    Step 1: Use Google Gemini to analyze the spec for missing details.
    """
    print("--- STEP 1: Google Gemini is analyzing the requirements... ---")
    
    spec = state['spec_text']
    
    prompt = f"""
    You are a Senior Solutions Architect. Analyze the following project requirement text.
    Identify technical gaps, missing acceptance criteria, and vague statements.
    
    REQUIREMENT TEXT:
    {spec}
    """
    
    # Invoke Gemini
    response = gemini_model.invoke([HumanMessage(content=prompt)])
    
    # Update the state with the analysis
    return {"analysis_gaps": response.content}

def draft_tickets_node(state: AgentState):
    """
    Step 2: Use Azure OpenAI to take the analysis and write Azure DevOps tickets.
    """
    print("--- STEP 2: Azure OpenAI is drafting Azure DevOps tickets... ---")
    
    analysis = state['analysis_gaps']
    original_spec = state['spec_text']
    
    prompt = f"""
    You are a Technical Product Owner. 
    Based on the original request and the Architect's gap analysis below, 
    write 3 structured Azure DevOps Work Items.
    
    Format them strictly as JSON with fields: 'Title', 'Description', 'Acceptance Criteria'.
    
    ORIGINAL REQUEST:
    {original_spec}
    
    ARCHITECT'S ANALYSIS:
    {analysis}
    """
    
    # Invoke Azure OpenAI
    response = azure_model.invoke([HumanMessage(content=prompt)])
    
    # Update the state with the final tickets
    return {"ado_tickets": response.content}

# --- THE GRAPH (The Architecture) ---
# This defines the workflow: Start -> Analyze -> Draft -> End

workflow = StateGraph(AgentState)

# Add our nodes
workflow.add_node("analyze_spec", analyze_requirements_node)
workflow.add_node("create_tickets", draft_tickets_node)

# Add edges (Connect the dots)
workflow.set_entry_point("analyze_spec") # Start here
workflow.add_edge("analyze_spec", "create_tickets") # Then go here
workflow.add_edge("create_tickets", END) # Then finish

# Compile the graph into a runnable application
app = workflow.compile()

# --- MAIN EXECUTION ---
if __name__ == "__main__":
    # Simulate a vague requirement input (typical PO scenario)
    sample_spec = """
    We need to migrate the 'Customer Loyalty' SQL database from on-prem 
    to the cloud. It needs to work with the new mobile app. 
    Make sure it's secure.
    """

    print(f"INPUT SPEC: {sample_spec.strip()}\n")
    
    # Run the graph
    result = app.invoke({"spec_text": sample_spec})
    
    print("\n\n################ FINAL OUTPUT ################\n")
    print(result['ado_tickets'])
    print("\n##############################################")